import base64, os, json, logging
from datetime import datetime
from fastapi import FastAPI, WebSocket
from fastapi.responses import PlainTextResponse, JSONResponse
from prometheus_client import Counter, Histogram, generate_latest, CONTENT_TYPE_LATEST
from apscheduler.schedulers.asyncio import AsyncIOScheduler
from pydantic import BaseModel
from cryptography.hazmat.primitives.ciphers import Cipher, algorithms, modes
from cryptography.hazmat.primitives import padding
from cryptography.hazmat.backends import default_backend

from opentelemetry import trace
from opentelemetry.sdk.resources import Resource
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.sdk.trace.export import BatchSpanProcessor
from opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter

resource = Resource.create({\"service.name\": \"mind-backend\"})
tp = TracerProvider(resource=resource)
tp.add_span_processor(BatchSpanProcessor(OTLPSpanExporter(endpoint=\"http://localhost:4318/v1/traces\")))
trace.set_tracer_provider(tp)
tracer = trace.get_tracer(__name__)

root_logger = logging.getLogger(\"mind\")
root_logger.setLevel(logging.INFO)
if not root_logger.handlers:
    h = logging.StreamHandler()
    f = logging.Formatter('%(message)s')
    h.setFormatter(f)
    root_logger.addHandler(h)

REQS = Counter('mind_requests_total', 'Total requests', ['route'])
LAT = Histogram('mind_request_latency_seconds', 'Latency', ['route'])

KEY = (os.getenv('LOG_AES_KEY') or 'this_is_32_bytes_key_for_demo_!').encode()[:32]
IV  = (os.getenv('LOG_AES_IV')  or 'this_is_16_bytes!').encode()[:16]

def aes256_encrypt(s: str) -> str:
    padder = padding.PKCS7(128).padder()
    pt = padder.update(s.encode()) + padder.finalize()
    cipher = Cipher(algorithms.AES(KEY), modes.CBC(IV), backend=default_backend())
    enc = cipher.encryptor()
    ct = enc.update(pt) + enc.finalize()
    return base64.b64encode(ct).decode()

app = FastAPI(title=\"MIND FIN PRO API\")

class SimInput(BaseModel):
    income: float
    expenses: float
    debt: float
    risk_profile: str | None = None
    mood: str | None = None

@app.get('/admin/metrics')
def metrics():
    return PlainTextResponse(generate_latest(), media_type=CONTENT_TYPE_LATEST)

@app.post('/simulate/performance')
def simulate(data: SimInput):
    with tracer.start_as_current_span(\"simulate.performance\"):
        pass

    score = max(0.0, min(100.0,
        (data.income - data.expenses) / max(1, data.income) * 100
        - (data.debt / max(1, data.income)) * 10))

    plan = {
        \"score\": round(score,2),
        \"actions\": [
            \"Reduzir 10% de gastos variáveis\",
            \"Quitar dívidas >2% a.m. primeiro\",
            \"Automatizar aporte 5% renda em reserva\"
        ],
        \"narrative\": \"Fluxo positivo moderado. Priorize amortização e crie colchão.\"
    }

    root_logger.info(json.dumps({
        \"event\": \"simulate_performance\",
        \"user_encrypted\": aes256_encrypt(f\"{data.risk_profile}|{data.mood}\"),
        \"score\": plan[\"score\"]
    }))
    return JSONResponse(plan)

@app.websocket('/ws/ai')
async def ws_ai(ws: WebSocket):
    await ws.accept()
    for chunk in [\"Conectado. IA carregando...\", \"Analisando dados...\", \"Detectando padrões...\", \"Plano pronto.\"]:
        await ws.send_text(chunk)
    await ws.close()

scheduler = AsyncIOScheduler()
def task_learning():
    root_logger.info(json.dumps({\"event\":\"bg_learning_tick\",\"ts\":datetime.utcnow().isoformat()}))
scheduler.add_job(task_learning, 'interval', seconds=30)

@app.on_event(\"startup\")
async def on_start():
    scheduler.start()